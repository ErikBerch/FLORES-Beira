{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FLORES Evaluation Model Runner\n",
    "\n",
    "This script runs the FLORES flood simulation numerous times, changing the input variables every time. The resulting file can be analyzed in the 'FLORES - Evaluation Model Analysis' script.\n",
    "\n",
    "The FLORES evaluation largely depends on the 'Exploratory Modelling and Analysis (EMA) Workbench', built and maintained by J.H. Kwakkel.\n",
    "\n",
    "Other used python-packages are:\n",
    "- mpld3\n",
    "- ipyparallel\n",
    "- pydotplus\n",
    "- seaborn\n",
    "- Graphviz\n",
    "- SALib\n",
    "- Platypus\n",
    "- Borg MOEA\n",
    "\n",
    "Version FLORES flood simulation: V1.1\n",
    "\n",
    "Version EMA-Workbench: V1.2.1 (26-08-2018)\n",
    "\n",
    "Last Updated: 21-08-2019\n",
    "\n",
    "## LOG\n",
    "The following evaluations have been run:\n",
    "    \n",
    "Date   ...     Evaluation     ...                              Storm  ...    Nr. strategies ...      Name\n",
    "\n",
    "<p>--/--/---- ... description   ...    # ...          #      ...             /name</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\ecvanberchum\\\\Surfdrive\\\\MODOS\\\\MODOS_model\\\\FLORES_main'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./Packages')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import (absolute_import, division,\n",
    "                        print_function, unicode_literals)\n",
    "\n",
    "\n",
    "\n",
    "from ema_workbench.em_framework import (RealParameter, ScalarOutcome, \n",
    "                           perform_experiments, CategoricalParameter, samplers, Scenario)\n",
    "\n",
    "from ema_workbench.util import (ema_logging)\n",
    "from ema_workbench import (Model, RealParameter, ScalarOutcome, Constant,\n",
    "                           ema_logging, MultiprocessingEvaluator)\n",
    "from ema_workbench.em_framework.model import (Replicator,BaseModel)\n",
    "from ema_workbench.em_framework.samplers import (MonteCarloSampler, FullFactorialSampler, LHSSampler,\n",
    "                       PartialFactorialSampler, sample_levers, sample_uncertainties)\n",
    "from ema_workbench.util import (save_results, load_results)\n",
    "\n",
    "from Library.simulation_calculations_beira import run_hydraulic_calculation\n",
    "from Library.simulation_definitions_beira import (Impact)\n",
    "\n",
    "import Library.simulation_data_beira as data\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from timeit import default_timer as timer\n",
    "import csv\n",
    "from scipy.integrate import trapz\n",
    "\n",
    "time_prep = timer()\n",
    "basins_master = data.load_basins(\"Library/input_data/region_layout_basins.csv\",\n",
    "                            \"Library/input_data/urban_development_scenarios.csv\")  # Regional Layout\n",
    "layers_master = data.load_layers(\"Library/input_data/region_layout_layers.csv\", basins_master)\n",
    "all_measures_master = data.load_measures(\"Library/input_data/flood_risk_reduction_measures.csv\")\n",
    "hydraulic_conditions_master = data.load_hydraulic_conditions(\"Library/input_data/hydraulic_boundary_conditions_surge_beira.csv\",\n",
    "                                                        \"Library/input_data/hydraulic_boundary_conditions_rain_beira.csv\")\n",
    "\n",
    "damage_curves = data.load_damage_curves('Library/input_data/global_flood_depth-damage_functions__30102017.xlsx', 'AFRICA',\n",
    "                                   'Mozambique', 'Object based', 1.30)\n",
    "data.load_basin_borders(basins_master, \"Library/input_data/region_layout_basin_borders.csv\")\n",
    "drainage_master = data.load_drainage_capacities(basins_master, 'Library/input_data/basins_drainage.csv', small_channel=6,\n",
    "                                           mid_channel=10, large_channel=35, low_drain=0, mid_drain=2, high_drain=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flood_simulation_model(return_period_storm = 0,    # 0, 2, 5, 10, 50, 100\n",
    "                             return_period_rain = 0,    # 0, 2, 5, 10, 50, 100\n",
    "                             struc_measure_coast_1 = 'none',  # 'Heighten dunes east','Sand supplements east', None\n",
    "                             struc_measure_coast_2 = 'none',  # 'Heighten dunes west','Floodwall west'', None\n",
    "                             struc_measure_inland_1 = 'none',  # 'Heighten inland road', None\n",
    "                             struc_measure_inland_2 = 'none',\n",
    "                             drainage_measure_1 = 'none',  # 'Second phase drainage', None\n",
    "                             drainage_measure_2 = 'none',   # 'Microdrainage, None\n",
    "                             retention_measure_1 = 'none',  # 'East retention', None\n",
    "                             retention_measure_2 = 'none',    # 'Maraza retention, None\n",
    "                             emergency_measure_1 = 'none',  # 'Improve evacuation', None\n",
    "                             emergency_measure_2 = 'none',    # 'Early warning system', None\n",
    "                             h_struc_measure_coast_1 = 0,  # 8-12\n",
    "                             h_struc_measure_coast_2 = 0,  # 8-12\n",
    "                             h_struc_measure_inland_1 = 0,  # 7-10\n",
    "                             h_struc_measure_inland_2 = 0,\n",
    "                             input_scenario_climate = 'none',  # 'high','low', 'none'\n",
    "                             input_scenario_development = 'none'  # 'high','low', 'none'\n",
    "                            ):\n",
    "        # added so we can add scenario information into the replicator\n",
    "    if return_period_rain == 'INFO':\n",
    "        scenario_info = str(input_scenario_climate) + ',' + str(input_scenario_development)\n",
    "        return [scenario_info]*3\n",
    "    \n",
    "        # start of model, loads simulation-specific data\n",
    "    hydraulic = data.get_hydraulic_boundary_conditions(hydraulic_conditions_master, return_period_storm, return_period_rain,\n",
    "                                                  input_scenario_climate)\n",
    "    region_layout = data.get_region_layout(basins_master, layers_master, input_scenario_development)\n",
    "    strategy = data.get_strategy(all_measures_master, region_layout,\n",
    "                            [struc_measure_coast_1, struc_measure_coast_2, struc_measure_inland_1, struc_measure_inland_2,\n",
    "                             drainage_measure_1, drainage_measure_2, retention_measure_1, retention_measure_2,\n",
    "                             emergency_measure_1, emergency_measure_2],\n",
    "                            [h_struc_measure_coast_1, h_struc_measure_coast_2, h_struc_measure_inland_1,\n",
    "                             h_struc_measure_inland_2])\n",
    "    impact = Impact()\n",
    "\n",
    "    # Builds and correctly names the scenarios\n",
    "    for sequence in [1, 3]:\n",
    "        region_layout.Layers[sequence].get_scenarios()\n",
    "    strategy.get_list_scenarios(region_layout)\n",
    "\n",
    "    # Hydraulic calculations, runs entire hydraulic simulation (pluvial and storm surge flooding)\n",
    "    run_hydraulic_calculation(region_layout, hydraulic, strategy)\n",
    "\n",
    "    strategy.get_probabilities(region_layout, hydraulic)\n",
    "\n",
    "    # Calculate cost of construction and repair\n",
    "    total_cost = strategy.get_construction_costs()\n",
    "\n",
    "    # Impact calculations, calculates expected damages and exposed population per basin and in total\n",
    "    impact.run_impact_calculations(region_layout, strategy, damage_curves)\n",
    "    risk_reduction = impact.TotalExpectedDamage\n",
    "    construction_cost = total_cost\n",
    "    affected_pop_reduction = impact.TotalExpectedExposedPop\n",
    "    \n",
    "    return risk_reduction, construction_cost, affected_pop_reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ready\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Created on\n",
    "\n",
    ".. codeauthor:: jhkwakkel <j.h.kwakkel (at) tudelft (dot) nl>\n",
    "'''\n",
    "class ReplicatorModel(Replicator, BaseModel):\n",
    "    pass\n",
    "\n",
    "def process_risk(data_risk):\n",
    "    D0_source = {'low,low': 9800000,  \n",
    "                 'low,high': 24092900, # not calibrated. don't use\n",
    "                 'high,low': 14980000,  \n",
    "                 'high,high': 31478200  # not calibrated. don't use\n",
    "                 }\n",
    "\n",
    "    scenario_info = data_risk.pop()\n",
    "    D0 = D0_source[scenario_info]  # Base case, storm: 0 year\n",
    "    data_risk.append(0)  # running the simulation without storm or rain is skipped\n",
    "    Prob_rain = [0, 0.01, 0.02, 0.1, 0.2, 1]\n",
    "    Prob_storm = [0, 0.01, 0.02, 0.1, 0.2, 1]\n",
    "    runs_per_hazard = len(Prob_rain) - 1\n",
    "    data_risk_array = np.reshape(data_risk, (runs_per_hazard, runs_per_hazard))\n",
    "\n",
    "    risk_conditional_storm = []\n",
    "    for count_storm, p_storm in enumerate(Prob_storm[0:5]):\n",
    "        tmp_conditional_damages = data_risk_array[count_storm]\n",
    "        conditional_damages = np.append(tmp_conditional_damages, tmp_conditional_damages[-1])\n",
    "        risk_conditional_storm.append(trapz(conditional_damages, Prob_rain))\n",
    "    risk_conditional_storm.append(risk_conditional_storm[-1])\n",
    "    risk = trapz(risk_conditional_storm, Prob_storm)\n",
    "    risk_reduction = (D0 - risk) / D0\n",
    "\n",
    "    return risk_reduction\n",
    "    \n",
    "def process_affected_people(data_people):\n",
    "\n",
    "    P0_source = {'low,low': 32800, \n",
    "                 'low,high': 80100,  #not calibrated. don't use\n",
    "                 'high,low': 48700, \n",
    "                 'high,high': 112100  #not calibrated. don't use\n",
    "                 }\n",
    "\n",
    "    scenario_info = data_people.pop()\n",
    "    P0 = P0_source[scenario_info]\n",
    "    data_people.append(0)\n",
    "\n",
    "    Prob_rain = [0, 0.01, 0.02, 0.1, 0.2, 1]\n",
    "    Prob_storm = [0, 0.01, 0.02, 0.1, 0.2, 1]\n",
    "    runs_per_hazard = len(Prob_rain) - 1\n",
    "    data_people_array = np.reshape(data_people, (runs_per_hazard, runs_per_hazard))\n",
    "\n",
    "    people_conditional_storm = []\n",
    "    for count_storm, p_storm in enumerate(Prob_storm[0:5]):\n",
    "        tmp_conditional_people = data_people_array[count_storm]\n",
    "        conditional_people = np.append(tmp_conditional_people, tmp_conditional_people[-1])\n",
    "        people_conditional_storm.append(trapz(conditional_people, Prob_rain))\n",
    "\n",
    "    people_conditional_storm.append(people_conditional_storm[-1])\n",
    "    affected_population = trapz(people_conditional_storm, Prob_storm)\n",
    "    affected_population_reduction = (P0 - affected_population) / P0\n",
    "\n",
    "    \n",
    "    return affected_population_reduction\n",
    "\n",
    "def pick_one(data):\n",
    "    return data[0]\n",
    "     \n",
    "def pick_50(data):\n",
    "    return data[2]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ema_logging.log_to_stderr(level=ema_logging.INFO)\n",
    "    model = ReplicatorModel('EvaluationModel', function=flood_simulation_model)\n",
    "       \n",
    "    model.replications = [{\"return_period_rain\":100,\"return_period_storm\":100},\n",
    "                      {\"return_period_rain\":50,\"return_period_storm\":100},\n",
    "                      {\"return_period_rain\":10,\"return_period_storm\":100},\n",
    "                      {\"return_period_rain\":5,\"return_period_storm\":100},\n",
    "                      {\"return_period_rain\":0,\"return_period_storm\":100}, \n",
    "                      {\"return_period_rain\":100,\"return_period_storm\":50},\n",
    "                      {\"return_period_rain\":50,\"return_period_storm\":50},\n",
    "                      {\"return_period_rain\":10,\"return_period_storm\":50},\n",
    "                      {\"return_period_rain\":5,\"return_period_storm\":50},\n",
    "                      {\"return_period_rain\":0,\"return_period_storm\":50},\n",
    "                      {\"return_period_rain\":100,\"return_period_storm\":10},\n",
    "                      {\"return_period_rain\":50,\"return_period_storm\":10},\n",
    "                      {\"return_period_rain\":10,\"return_period_storm\":10},\n",
    "                      {\"return_period_rain\":5,\"return_period_storm\":10},\n",
    "                      {\"return_period_rain\":0,\"return_period_storm\":10},\n",
    "                      {\"return_period_rain\":100,\"return_period_storm\":5},\n",
    "                      {\"return_period_rain\":50,\"return_period_storm\":5},\n",
    "                      {\"return_period_rain\":10,\"return_period_storm\":5},\n",
    "                      {\"return_period_rain\":5,\"return_period_storm\":5},\n",
    "                      {\"return_period_rain\":0,\"return_period_storm\":5},\n",
    "                      {\"return_period_rain\":100,\"return_period_storm\":0},\n",
    "                      {\"return_period_rain\":50,\"return_period_storm\":0},\n",
    "                      {\"return_period_rain\":10,\"return_period_storm\":0},\n",
    "                      {\"return_period_rain\":5,\"return_period_storm\":0},\n",
    "                      {\"return_period_rain\":'INFO',\"return_period_storm\":'INFO'}]\n",
    "\n",
    "\n",
    "\n",
    "    # set levers\n",
    "    model.levers = [CategoricalParameter('struc_measure_coast_1',['Heighten_dunes_east','Sand_supplements_east','none']),\n",
    "                    CategoricalParameter('struc_measure_coast_2',['Heighten_dunes_west','Floodwall_west', 'none']),\n",
    "                    CategoricalParameter('struc_measure_inland_1',['Heighten_inland_road', 'none']),\n",
    "                    CategoricalParameter('drainage_measure_1',['Second_phase_drainage','none']),\n",
    "                    CategoricalParameter('drainage_measure_2',['Microdrainage', 'none']),\n",
    "                    CategoricalParameter('retention_measure_1',['East_retention', 'none']),\n",
    "                    CategoricalParameter('retention_measure_2',['Chota_retention', 'none']),\n",
    "                    CategoricalParameter('emergency_measure_1',['Improve_evacuation', 'none']),\n",
    "                    CategoricalParameter('emergency_measure_2',['Early_warning_system', 'none']),                   \n",
    "                    RealParameter(\"h_struc_measure_coast_1\", 9, 12),\n",
    "                    RealParameter(\"h_struc_measure_coast_2\", 8, 12),\n",
    "                    RealParameter(\"h_struc_measure_inland_1\", 7.5, 9)                    \n",
    "                    ]\n",
    "    \n",
    "    # set constants \n",
    "    model.constants = [Constant('input_scenario_development','low'),\n",
    "                       ]\n",
    "    \n",
    "    # set uncertainties, future scenarios\n",
    "    model.uncertainties = [CategoricalParameter('input_scenario_climate',['low','high']),\n",
    "                          ]\n",
    "    \n",
    "    #specification of the outcomes\n",
    "    model.outcomes = [ScalarOutcome(\"risk_reduction\", function=process_risk),\n",
    "                      ScalarOutcome(\"construction_costs\", function=pick_one),\n",
    "                      ScalarOutcome(\"affected_pop_reduction\", function=process_affected_people)]\n",
    "    \n",
    "\n",
    "    nr_strategies = 10\n",
    "    \n",
    "    fn = './data/{} experiments_FLORES_Beira_21-08-2019-2_scenarios.tar.gz'.format(nr_strategies)\n",
    "print('ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] performing 2 scenarios * 10 policies * 1 model(s) = 20 experiments\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 1 cases completed\n",
      "[MainProcess/INFO] 2 cases completed\n",
      "[MainProcess/INFO] 3 cases completed\n",
      "[MainProcess/INFO] 4 cases completed\n",
      "[MainProcess/INFO] 5 cases completed\n",
      "[MainProcess/INFO] 6 cases completed\n",
      "[MainProcess/INFO] 7 cases completed\n",
      "[MainProcess/INFO] 8 cases completed\n",
      "[MainProcess/INFO] 9 cases completed\n",
      "[MainProcess/INFO] 10 cases completed\n",
      "[MainProcess/INFO] 11 cases completed\n",
      "[MainProcess/INFO] 12 cases completed\n",
      "[MainProcess/INFO] 13 cases completed\n",
      "[MainProcess/INFO] 14 cases completed\n",
      "[MainProcess/INFO] 15 cases completed\n",
      "[MainProcess/INFO] 16 cases completed\n",
      "[MainProcess/INFO] 17 cases completed\n",
      "[MainProcess/INFO] 18 cases completed\n",
      "[MainProcess/INFO] 19 cases completed\n",
      "[MainProcess/INFO] 20 cases completed\n",
      "[MainProcess/INFO] experiments finished\n",
      "[MainProcess/INFO] results saved successfully to D:\\ecvanberchum\\Surfdrive\\MODOS\\MODOS_model\\FLORES_main\\data\\10 experiments_FLORES_Beira_21-08-2019-2_scenarios.tar.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "4802.800773702332\n"
     ]
    }
   ],
   "source": [
    "# Single processor runner\n",
    "\n",
    "start = timer()\n",
    "try:\n",
    "    # check whether it overwrites another file\n",
    "    results = load_results(fn)\n",
    "except FileNotFoundError:\n",
    "    # generate some random policies by sampling over levers\n",
    "    system_configurations = samplers.sample_levers(model, nr_strategies)\n",
    "    \n",
    "    results = perform_experiments(model, scenarios=4, policies=nr_strategies, \n",
    "                                  uncertainty_sampling='ff',reporting_interval=1) \n",
    "    save_results(results, fn)\n",
    "\n",
    "print(\"done\")\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi processor runner\n",
    "\n",
    "from ema_workbench.em_framework.evaluators import (MultiprocessingEvaluator)\n",
    "\n",
    "start = timer()\n",
    "try:\n",
    "    results = load_results(fn)\n",
    "except FileNotFoundError:\n",
    "    system_configurations = samplers.sample_levers(model, nr_strategies)    \n",
    "    \n",
    "    with MultiprocessingEvaluator(model) as evaluator:\n",
    "        evaluator.n_processes = 2\n",
    "        evaluator.perform_experiments(scenarios=4, policies=nr_strategies, \n",
    "                                  uncertainty_sampling='ff',reporting_interval=1)\n",
    "        print(\"here\")\n",
    "    save_results(results, fn)\n",
    "\n",
    "print(\"done\")\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
